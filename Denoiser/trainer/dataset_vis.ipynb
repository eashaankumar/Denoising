{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb40518-3e40-4b16-bccc-d87faac668c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0070cb13-9b92-4978-b3d7-1b3524d7917a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /workspace/CNN_240p_Denoiser/val on 3 threads\n",
      "Thread started\n",
      "Thread started\n",
      "Thread started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "datapoints 3:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "CNN_240p_Denoiser-val-(0, 3):   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "\n",
      "datapoints 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "CNN_240p_Denoiser-val-(0, 3):   0%|          | 0/3 [00:00<?, ?it/s, image=['CNN_240_Denoiser-albedo-0.jpg', 'CNN_240_Denoiser-converged-0.jpg', 'CNN_240_Denoiser-depth-0.jpg', 'CNN_240_Denoiser-emission-0.jpg', 'CNN_240_Denoiser-extcoMetal-0.jpg', 'CNN_240_Denoiser-ior-0.jpg', 'CNN_240_Denoiser-k-0.jpg', 'CNN_240_Denoiser-noisy-0.jpg', 'CNN_240_Denoiser-normals-0.jpg', 'CNN_240_Denoiser-roughSmooth-0.jpg', 'CNN_240_Denoiser-shape-0.jpg', 'CNN_240_Denoiser-specular-0.jpg']]\n",
      "CNN_240p_Denoiser-val-(6, 10):   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "CNN_240p_Denoiser-val-(0, 3):   0%|          | 0/3 [00:00<?, ?it/s, image=['CNN_240_Denoiser-albedo-1.jpg', 'CNN_240_Denoiser-converged-1.jpg', 'CNN_240_Denoiser-depth-1.jpg', 'CNN_240_Denoiser-emission-1.jpg', 'CNN_240_Denoiser-extcoMetal-1.jpg', 'CNN_240_Denoiser-ior-1.jpg', 'CNN_240_Denoiser-k-1.jpg', 'CNN_240_Denoiser-noisy-1.jpg', 'CNN_240_Denoiser-normals-1.jpg', 'CNN_240_Denoiser-roughSmooth-1.jpg', 'CNN_240_Denoiser-shape-1.jpg', 'CNN_240_Denoiser-specular-1.jpg']]iser-specular-100.jpg']]\u001b[A\u001b[A\n",
      "CNN_240p_Denoiser-val-(6, 10):   0%|          | 0/4 [00:00<?, ?it/s, image=['CNN_240_Denoiser-albedo-1002.jpg', 'CNN_240_Denoiser-converged-1002.jpg', 'CNN_240_Denoiser-depth-1002.jpg', 'CNN_240_Denoiser-emission-1002.jpg', 'CNN_240_Denoiser-extcoMetal-1002.jpg', 'CNN_240_Denoiser-ior-1002.jpg', 'CNN_240_Denoiser-k-1002.jpg', 'CNN_240_Denoiser-noisy-1002.jpg', 'CNN_240_Denoiser-normals-1002.jpg', 'CNN_240_Denoiser-roughSmooth-1002.jpg', 'CNN_240_Denoiser-shape-1002.jpg', 'CNN_240_Denoiser-specular-1002.jpg']]\u001b[A\n",
      "\n",
      "CNN_240p_Denoiser-val-(0, 3):   0%|          | 0/3 [00:00<?, ?it/s, image=['CNN_240_Denoiser-albedo-10.jpg', 'CNN_240_Denoiser-converged-10.jpg', 'CNN_240_Denoiser-depth-10.jpg', 'CNN_240_Denoiser-emission-10.jpg', 'CNN_240_Denoiser-extcoMetal-10.jpg', 'CNN_240_Denoiser-ior-10.jpg', 'CNN_240_Denoiser-k-10.jpg', 'CNN_240_Denoiser-noisy-10.jpg', 'CNN_240_Denoiser-normals-10.jpg', 'CNN_240_Denoiser-roughSmooth-10.jpg', 'CNN_240_Denoiser-shape-10.jpg', 'CNN_240_Denoiser-specular-10.jpg']]ser-specular-1000.jpg']]\u001b[A\u001b[A\n",
      "CNN_240p_Denoiser-val-(0, 3): 100%|██████████| 3/3 [00:00<00:00, 108.46it/s, image=['CNN_240_Denoiser-albedo-10.jpg', 'CNN_240_Denoiser-converged-10.jpg', 'CNN_240_Denoiser-depth-10.jpg', 'CNN_240_Denoiser-emission-10.jpg', 'CNN_240_Denoiser-extcoMetal-10.jpg', 'CNN_240_Denoiser-ior-10.jpg', 'CNN_240_Denoiser-k-10.jpg', 'CNN_240_Denoiser-noisy-10.jpg', 'CNN_240_Denoiser-normals-10.jpg', 'CNN_240_Denoiser-roughSmooth-10.jpg', 'CNN_240_Denoiser-shape-10.jpg', 'CNN_240_Denoiser-specular-10.jpg']]ular-1003.jpg']]\u001b[A\n",
      "\n",
      "\n",
      "CNN_240p_Denoiser-val-(3, 6):   0%|          | 0/3 [00:00<?, ?it/s, image=['CNN_240_Denoiser-albedo-1001.jpg', 'CNN_240_Denoiser-converged-1001.jpg', 'CNN_240_Denoiser-depth-1001.jpg', 'CNN_240_Denoiser-emission-1001.jpg', 'CNN_240_Denoiser-extcoMetal-1001.jpg', 'CNN_240_Denoiser-ior-1001.jpg', 'CNN_240_Denoiser-k-1001.jpg', 'CNN_240_Denoiser-noisy-1001.jpg', 'CNN_240_Denoiser-normals-1001.jpg', 'CNN_240_Denoiser-roughSmooth-1001.jpg', 'CNN_240_Denoiser-shape-1001.jpg', 'CNN_240_Denoiser-specular-1001.jpg']]\u001b[A\u001b[A\n",
      "CNN_240p_Denoiser-val-(3, 6): 100%|██████████| 3/3 [00:00<00:00, 110.18it/s, image=['CNN_240_Denoiser-albedo-1001.jpg', 'CNN_240_Denoiser-converged-1001.jpg', 'CNN_240_Denoiser-depth-1001.jpg', 'CNN_240_Denoiser-emission-1001.jpg', 'CNN_240_Denoiser-extcoMetal-1001.jpg', 'CNN_240_Denoiser-ior-1001.jpg', 'CNN_240_Denoiser-k-1001.jpg', 'CNN_240_Denoiser-noisy-1001.jpg', 'CNN_240_Denoiser-normals-1001.jpg', 'CNN_240_Denoiser-roughSmooth-1001.jpg', 'CNN_240_Denoiser-shape-1001.jpg', 'CNN_240_Denoiser-specular-1001.jpg']]\n",
      "\n",
      "CNN_240p_Denoiser-val-(6, 10): 100%|██████████| 4/4 [00:00<00:00, 111.63it/s, image=['CNN_240_Denoiser-albedo-1005.jpg', 'CNN_240_Denoiser-converged-1005.jpg', 'CNN_240_Denoiser-depth-1005.jpg', 'CNN_240_Denoiser-emission-1005.jpg', 'CNN_240_Denoiser-extcoMetal-1005.jpg', 'CNN_240_Denoiser-ior-1005.jpg', 'CNN_240_Denoiser-k-1005.jpg', 'CNN_240_Denoiser-noisy-1005.jpg', 'CNN_240_Denoiser-normals-1005.jpg', 'CNN_240_Denoiser-roughSmooth-1005.jpg', 'CNN_240_Denoiser-shape-1005.jpg', 'CNN_240_Denoiser-specular-1005.jpg']]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data('/workspace/CNN_240p_Denoiser/val', batch_size=4, num_dataset_threads=3, data_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9472dcd-6f11-4a94-bc95-d91d7bf817c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def show_images(res):\n",
    "    grid_img = torchvision.utils.make_grid(res, nrow=5)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "\n",
    "def record_imgs(noisy, tru, pred):\n",
    "    assert len(tru.shape) == 4\n",
    "    assert tru.shape == pred.shape\n",
    "    final = torch.zeros(3 * tru.shape[0], tru.shape[1], tru.shape[2], tru.shape[3])\n",
    "    j = 0\n",
    "    for i in range(tru.shape[0]):\n",
    "        final[j] = noisy[i]\n",
    "        final[j+1] = tru[i]\n",
    "        final[j+2] = pred[i]\n",
    "        j += 3\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1daecb-dea6-4d8d-9d90-23d926e3db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 240, 426])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m shape \u001b[38;5;241m=\u001b[39m buffer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m glass_data, standard_data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getshapemasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m glass_data \u001b[38;5;241m=\u001b[39m glass_data\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m standard_data \u001b[38;5;241m=\u001b[39m standard_data\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/workspace/Denoising/Denoiser/trainer/data.py:78\u001b[0m, in \u001b[0;36mCNN_SD_Denoiser_Dataset._getshapemasks\u001b[0;34m(self, shapebuffer)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getshapemasks\u001b[39m(\u001b[38;5;28mself\u001b[39m, shapebuffer):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapebuffer\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 78\u001b[0m         glass_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(shapebuffer[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mabs(shapebuffer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mabs(shapebuffer[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-1\u001b[39m\n\u001b[1;32m     79\u001b[0m         standard_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(shapebuffer[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mabs(shapebuffer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mabs(shapebuffer[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-1\u001b[39m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m glass_data, standard_data\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "for buffer in dataset:\n",
    "    print(buffer['shape'].shape)\n",
    "    shape = buffer['shape'][0]\n",
    "    glass_data, standard_data = dataset.dataset._getshapemasks(shape)\n",
    "    glass_data = glass_data.repeat(3, 1, 1)\n",
    "    standard_data = standard_data.repeat(3, 1, 1)\n",
    "    show_images(record_imgs(shape[None, :, :, :], glass_data[None, :, :, :], standard_data[None, :, :, :]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db7f62-18e8-4320-a488-f110acddb6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c85b679-4ecb-4cda-916e-6c8eb81a5ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
